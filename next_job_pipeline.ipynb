{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline to process user input and return possible future jobs\n",
    "this notebook contains several parts that process current job description entered by user and return suggestions of future jobs.\n",
    "<br>1) preprocess and vectorize text in user input.\n",
    "<br>2) extract document topic matrix for user's current job (job i).\n",
    "<br>3) calculate topic weights of future job (job i+1) by multiplying topic weight matrix of job i with transition matrix.\n",
    "<br>4) find jobs in dataset that are most similar to predicted future job, retrieve title, top skills (which are top topics), and keywords of each similar job in dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.decomposition import NMF\n",
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open('work_exp_train.pkl', 'rb'))\n",
    "transition_mat = pickle.load(open('transition_mat.pkl', 'rb'))\n",
    "vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))\n",
    "nmf = pickle.load(open('nmf.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume_id</th>\n",
       "      <th>job_id</th>\n",
       "      <th>job_title_processed</th>\n",
       "      <th>job_description_processed</th>\n",
       "      <th>title_and_desc</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>Topic 10</th>\n",
       "      <th>Topic 11</th>\n",
       "      <th>Topic 12</th>\n",
       "      <th>Topic 13</th>\n",
       "      <th>Topic 14</th>\n",
       "      <th>Topic 15</th>\n",
       "      <th>Topic 16</th>\n",
       "      <th>Topic 17</th>\n",
       "      <th>Topic 18</th>\n",
       "      <th>Topic 19</th>\n",
       "      <th>Topic 20</th>\n",
       "      <th>highest_topic1</th>\n",
       "      <th>highest_topic2</th>\n",
       "      <th>highest_topic3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>data scientist</td>\n",
       "      <td>manager smart solution team information planni...</td>\n",
       "      <td>data scientist manager smart solution team inf...</td>\n",
       "      <td>0.374065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.258667</td>\n",
       "      <td>0.030413</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Topic 1</td>\n",
       "      <td>Topic 14</td>\n",
       "      <td>Topic 17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>business inteligence consultant</td>\n",
       "      <td>social medium analysis participate development...</td>\n",
       "      <td>business inteligence consultant social medium ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094456</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121584</td>\n",
       "      <td>0.062855</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124647</td>\n",
       "      <td>0.182327</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Topic 5</td>\n",
       "      <td>Topic 16</td>\n",
       "      <td>Topic 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>director business relation</td>\n",
       "      <td>gimme data scientist business solution present...</td>\n",
       "      <td>director business relation gimme data scientis...</td>\n",
       "      <td>0.043636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.406016</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.093207</td>\n",
       "      <td>0.240388</td>\n",
       "      <td>0.050646</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.154823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Topic 5</td>\n",
       "      <td>Topic 8</td>\n",
       "      <td>Topic 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>senior data analyst customer interaction decis...</td>\n",
       "      <td>sa fulltime translated business objective data...</td>\n",
       "      <td>senior data analyst customer interaction decis...</td>\n",
       "      <td>0.010189</td>\n",
       "      <td>0.066499</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.042836</td>\n",
       "      <td>0.210310</td>\n",
       "      <td>0.036869</td>\n",
       "      <td>0.356958</td>\n",
       "      <td>0.074922</td>\n",
       "      <td>0.055022</td>\n",
       "      <td>0.013159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103456</td>\n",
       "      <td>0.015330</td>\n",
       "      <td>0.010051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Topic 7</td>\n",
       "      <td>Topic 5</td>\n",
       "      <td>Topic 15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>freelance developer</td>\n",
       "      <td>toronto canada completed freelancer project in...</td>\n",
       "      <td>freelance developer toronto canada completed f...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.462758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122256</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057464</td>\n",
       "      <td>0.028745</td>\n",
       "      <td>0.038407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>Topic 3</td>\n",
       "      <td>Topic 7</td>\n",
       "      <td>Topic 10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   resume_id  job_id                                job_title_processed  \\\n",
       "0          1       0                                     data scientist   \n",
       "1          1       1                    business inteligence consultant   \n",
       "2          2       0                         director business relation   \n",
       "3          2       1  senior data analyst customer interaction decis...   \n",
       "4          3       0                                freelance developer   \n",
       "\n",
       "                           job_description_processed  \\\n",
       "0  manager smart solution team information planni...   \n",
       "1  social medium analysis participate development...   \n",
       "2  gimme data scientist business solution present...   \n",
       "3  sa fulltime translated business objective data...   \n",
       "4  toronto canada completed freelancer project in...   \n",
       "\n",
       "                                      title_and_desc   Topic 1   Topic 2  \\\n",
       "0  data scientist manager smart solution team inf...  0.374065  0.000000   \n",
       "1  business inteligence consultant social medium ...  0.000000  0.000000   \n",
       "2  director business relation gimme data scientis...  0.043636  0.000000   \n",
       "3  senior data analyst customer interaction decis...  0.010189  0.066499   \n",
       "4  freelance developer toronto canada completed f...  0.000000  0.000000   \n",
       "\n",
       "    Topic 3   Topic 4   Topic 5   Topic 6   Topic 7   Topic 8   Topic 9  \\\n",
       "0  0.000000  0.000000  0.025764  0.000000  0.086130  0.000000  0.000000   \n",
       "1  0.094456  0.000000  0.283788  0.000000  0.019943  0.000000  0.106125   \n",
       "2  0.000000  0.000000  0.406016  0.002058  0.093207  0.240388  0.050646   \n",
       "3  0.004399  0.042836  0.210310  0.036869  0.356958  0.074922  0.055022   \n",
       "4  0.462758  0.000000  0.000000  0.000000  0.267470  0.000000  0.000000   \n",
       "\n",
       "   Topic 10  Topic 11  Topic 12  Topic 13  Topic 14  Topic 15  Topic 16  \\\n",
       "0  0.041831  0.000000  0.060487       0.0  0.258667  0.030413  0.000000   \n",
       "1  0.000000  0.121584  0.062855       0.0  0.000000  0.124647  0.182327   \n",
       "2  0.000000  0.000000  0.000000       0.0  0.009227  0.154823  0.000000   \n",
       "3  0.013159  0.000000  0.000000       0.0  0.000000  0.103456  0.015330   \n",
       "4  0.122256  0.020006  0.002502       0.0  0.000000  0.057464  0.028745   \n",
       "\n",
       "   Topic 17  Topic 18  Topic 19  Topic 20 highest_topic1 highest_topic2  \\\n",
       "0  0.122643       0.0       0.0  0.000000        Topic 1       Topic 14   \n",
       "1  0.004276       0.0       0.0  0.000000        Topic 5       Topic 16   \n",
       "2  0.000000       0.0       0.0  0.000000        Topic 5        Topic 8   \n",
       "3  0.010051       0.0       0.0  0.000000        Topic 7        Topic 5   \n",
       "4  0.038407       0.0       0.0  0.000393        Topic 3        Topic 7   \n",
       "\n",
       "  highest_topic3  \n",
       "0       Topic 17  \n",
       "1       Topic 15  \n",
       "2       Topic 15  \n",
       "3       Topic 15  \n",
       "4       Topic 10  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\" preprocess text: remove special characters, remove digits, tokenize,\n",
    "    lowercase, remove stopwords, lemmatize\n",
    "    \"\"\"\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    stopwords_en = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "    text = re.sub('[^a-zA-Z]', ' ', text )\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token not in stopwords_en]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_job_topics(description, vectorizer, model, transition_matrix):\n",
    "    \"\"\"get document topic matrix for current job description entered by user\n",
    "    and compute document topic matrix for future job by multiplying\n",
    "    current job topic matrix with transition matrix\n",
    "    description -- new job description to be analyzed\n",
    "    vectorizer -- vectorizer for text processing\n",
    "    model -- nmf model\n",
    "    transition_matrix -- probabilities of transitioning from each of 20 topics\n",
    "    at job i to each of 20 topics at job i+1\n",
    "    \"\"\"\n",
    "    desc = preprocess(description)\n",
    "    desc_vec = vectorizer.transform([desc])\n",
    "    # get topic weights for description of current job\n",
    "    desc_nmf = model.transform(desc_vec)\n",
    "    # normalize topic weights so that they sum up to 1 \n",
    "    desc_nmf = desc_nmf/np.sum(desc_nmf)\n",
    "    \n",
    "    # calculate document topic matrix for next job\n",
    "    next_job_topics = np.dot(desc_nmf, transition_matrix)\n",
    "    \n",
    "    return next_job_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_similarity(topic_weights1, topic_weights2):\n",
    "    \"\"\"return cosine similarity between two jobs each represented by topic weights\n",
    "    topic_weights1 -- 1X20 matrix (20 topics)\n",
    "    topic_weights2 -- 1X20 matrix (20 topics)\n",
    "    \"\"\"\n",
    "    similarity = np.dot(topic_weights1, topic_weights2.T) \\\n",
    "                 /(np.linalg.norm(topic_weights1)*np.linalg.norm(topic_weights2))\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_job_output(description, vectorizer, model, transition_matrix, df):\n",
    "    \"\"\"find 6 jobs in dataset that are most similar to predicted future job,\n",
    "    return title, top 3 topics/skills of the 6 jobs, and keywords in \n",
    "    each of the 6 job descriptions. \n",
    "    \"\"\"\n",
    "    # topic weights of predicted future job\n",
    "    next_job = next_job_topics(description, vectorizer, model, transition_matrix)\n",
    "    \n",
    "    # cosine similarity between user input and jobs in dataset\n",
    "    topic_cols = [col for col in df.columns if 'Topic' in col]\n",
    "    topics_all = df[topic_cols].values\n",
    "    for i in range(len(df)):\n",
    "        df.loc[i, 'similarity'] = job_similarity(topics_all[i], next_job)\n",
    "    \n",
    "    # 6 most similar jobs\n",
    "    df6 = df.sort_values(by=['similarity'], ascending=False)[:6].reset_index(drop=True)\n",
    "    # get keywords from each job description\n",
    "    df6['keyterms'] = df6['job_description_processed'].apply(lambda x: keywords(x, ratio=0.18, words=None, split=False, scores=False, pos_filter=None, lemmatize=True))\n",
    "    df6['keyterm_list'] = df6['keyterms'].apply(lambda x: ' '.join(x.split('\\n')))\n",
    "    \n",
    "    topic_dict = {'Topic 1':'data warehousing', 'Topic 2':'project management',\n",
    "                  'Topic 3':'web development', 'Topic 4':'network management',\n",
    "                  'Topic 5':'statistical analysis', 'Topic 6':'product testing',\n",
    "                  'Topic 7':'machine learning', 'Topic 8': 'customer support',\n",
    "                  'Topic 9':'business solutions', 'Topic 10':'management/leadership',\n",
    "                  'Topic 11': 'systems management', 'Topic 12': 'enterprise data architecture',\n",
    "                  'Topic 13': 'IT technical support', 'Topic 14': 'big data tools',\n",
    "                  'Topic 15': 'marketing', 'Topic 16': 'data reporting',\n",
    "                  'Topic 17': 'academic research', 'Topic 18': 'database management',\n",
    "                  'Topic 19': 'SQL server tools', 'Topic 20': 'client relationship'}\n",
    "    \n",
    "    example_list = []\n",
    "    for i in range(6):\n",
    "        job_title = df6.loc[i, 'job_title_processed']\n",
    "        highest_topic1 = df6.loc[i, 'highest_topic1']\n",
    "        highest_topic2 = df6.loc[i, 'highest_topic2']\n",
    "        highest_topic3 = df6.loc[i, 'highest_topic3']\n",
    "        keyterms = df6.loc[i, 'keyterm_list']\n",
    "        example = [job_title, topic_dict[highest_topic1], topic_dict[highest_topic2], topic_dict[highest_topic3], keyterms]\n",
    "        example_list.append(example)\n",
    "    \n",
    "    return example_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = 'Conceptualize the technology process workflow and manage a team of software developers. Improve the existing regression models (neural networks) written in R and suggest new ways to implement in Python and TensorFlow. Deploy the services on Google Cloud with SQL support and use C# for client/server programing and ASP pages.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = next_job_output(description, vectorizer, nmf, transition_mat, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['consultant bi data scientist',\n",
       "  'machine learning',\n",
       "  'data warehouse/governance',\n",
       "  'big data tools',\n",
       "  'data management analysis solution energy development ssis package configuration include modeling support performance measurement failure detection report dashboard network visualization python script scale design database source equipment electrical topological web sparql rdf hadoop integrate time machine meter participated analytics process'],\n",
       " ['lead data scientist algorithm development',\n",
       "  'machine learning',\n",
       "  'client relationship',\n",
       "  'SQL server tools',\n",
       "  'way use predictive regression device given programing asp research phase'],\n",
       " ['kpi manager',\n",
       "  'machine learning',\n",
       "  'data reporting',\n",
       "  'data warehouse/governance',\n",
       "  'kpis developed modeling scorecard security metadata page data primarily definition analyze fix custom financial'],\n",
       " ['junior software developer',\n",
       "  'machine learning',\n",
       "  'project management',\n",
       "  'network infrastructure',\n",
       "  'domain update internet malicious organizing sinkhole assist maintain necessary report project'],\n",
       " ['geospatial analyst team prime',\n",
       "  'project management',\n",
       "  'financial analytics',\n",
       "  'big data tools',\n",
       "  'area mapping project geospatial data managed type store led arcgis generated field department collected script sql implemented customized spatial intelligence team geo unit location produced process different test application large help internal digital staff postal code desired responsible developer table network census upper server junior online useful software'],\n",
       " ['research assistant',\n",
       "  'machine learning',\n",
       "  'system management',\n",
       "  'web app development',\n",
       "  'duration analyzed developed efficient time article guarantee based'],\n",
       " ['data analyst',\n",
       "  'network infrastructure',\n",
       "  'data warehouse/governance',\n",
       "  'customer support',\n",
       "  'data service troubleshoot hostname management intria microsoft outlook report'],\n",
       " ['engineer',\n",
       "  'machine learning',\n",
       "  'data warehouse/governance',\n",
       "  'IT technical support',\n",
       "  'design engineer water supply'],\n",
       " ['data scientist intern',\n",
       "  'machine learning',\n",
       "  'SQL server tools',\n",
       "  'big data tools',\n",
       "  'news processed cloud based statistical information'],\n",
       " ['electrical firmware lead',\n",
       "  'data warehouse/governance',\n",
       "  'web app development',\n",
       "  'machine learning',\n",
       "  'sensor designed unit connected data output tool']]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
